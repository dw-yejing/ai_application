{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import PIL.Image as Image\n",
    "import numpy as np\n",
    "from paddle.io import Dataset\n",
    "\n",
    "# 图片信息配置 - 通道数、高度、宽度\n",
    "IMAGE_SHAPE_C = 3\n",
    "IMAGE_SHAPE_H = 30\n",
    "IMAGE_SHAPE_W = 70\n",
    "# 数据集图片中标签长度最大值设置 - 因图片中均为4个字符，故该处填写为4即可\n",
    "LABEL_MAX_LEN = 4\n",
    "\n",
    "\n",
    "class Reader(Dataset):\n",
    "    def __init__(self, data_path: str, is_val: bool = False):\n",
    "        \"\"\"\n",
    "        数据读取Reader\n",
    "        :param data_path: Dataset路径\n",
    "        :param is_val: 是否为验证集\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.data_path = data_path\n",
    "        # 读取Label字典\n",
    "        with open(os.path.join(self.data_path, \"label_dict.txt\"), \"r\", encoding=\"utf-8\") as f:\n",
    "            self.info = eval(f.read())\n",
    "        # 获取文件名列表\n",
    "        self.img_paths = [img_name for img_name in self.info]\n",
    "        # 将数据集后1024张图片设置为验证集，当is_val为真时img_path切换为后1024张\n",
    "        self.img_paths = self.img_paths[-1024:] if is_val else self.img_paths[:-1024]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # 获取第index个文件的文件名以及其所在路径\n",
    "        file_name = self.img_paths[index]\n",
    "        file_path = os.path.join(self.data_path, file_name)\n",
    "        # 捕获异常 - 在发生异常时终止训练\n",
    "        try:\n",
    "            # 使用Pillow来读取图像数据\n",
    "            img = Image.open(file_path)\n",
    "            # 转为Numpy的array格式并整体除以255进行归一化\n",
    "            img = np.array(img, dtype=\"float32\").reshape((IMAGE_SHAPE_C, IMAGE_SHAPE_H, IMAGE_SHAPE_W)) / 255\n",
    "        except Exception as e:\n",
    "            raise Exception(file_name + \"\\t文件打开失败，请检查路径是否准确以及图像文件完整性，报错信息如下:\\n\" + str(e))\n",
    "        # 读取该图像文件对应的Label字符串，并进行处理\n",
    "        label = self.info[file_name]\n",
    "        label = list(label)\n",
    "        # 将label转化为Numpy的array格式\n",
    "        label = np.array(label, dtype=\"int32\")\n",
    "\n",
    "        return img, label\n",
    "\n",
    "    def __len__(self):\n",
    "        # 返回每个Epoch中图片数量\n",
    "        return len(self.img_paths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import paddle\n",
    "\n",
    "# 分类数量设置 - 因数据集中共包含0~9共10种数字+分隔符，所以是11分类任务\n",
    "CLASSIFY_NUM = 11\n",
    "\n",
    "# 定义输入层，shape中第0维使用-1则可以在预测时自由调节batch size\n",
    "input_define = paddle.static.InputSpec(shape=[-1, IMAGE_SHAPE_C, IMAGE_SHAPE_H, IMAGE_SHAPE_W],\n",
    "                                   dtype=\"float32\",\n",
    "                                   name=\"img\")\n",
    "\n",
    "# 定义网络结构\n",
    "class Net(paddle.nn.Layer):\n",
    "    def __init__(self, is_infer: bool = False):\n",
    "        super().__init__()\n",
    "        self.is_infer = is_infer\n",
    "\n",
    "        # 定义一层3x3卷积+BatchNorm\n",
    "        self.conv1 = paddle.nn.Conv2D(in_channels=IMAGE_SHAPE_C,\n",
    "                                  out_channels=32,\n",
    "                                  kernel_size=3)\n",
    "        self.bn1 = paddle.nn.BatchNorm2D(32)\n",
    "        # 定义一层步长为2的3x3卷积进行下采样+BatchNorm\n",
    "        self.conv2 = paddle.nn.Conv2D(in_channels=32,\n",
    "                                  out_channels=64,\n",
    "                                  kernel_size=3,\n",
    "                                  stride=2)\n",
    "        self.bn2 = paddle.nn.BatchNorm2D(64)\n",
    "        # 定义一层1x1卷积压缩通道数，输出通道数设置为比LABEL_MAX_LEN稍大的定值可获取更优效果，当然也可设置为LABEL_MAX_LEN\n",
    "        self.conv3 = paddle.nn.Conv2D(in_channels=64,\n",
    "                                  out_channels=LABEL_MAX_LEN + 4,\n",
    "                                  kernel_size=1)\n",
    "        # 定义全连接层，压缩并提取特征（可选）\n",
    "        self.linear = paddle.nn.Linear(in_features=429,\n",
    "                                   out_features=128)\n",
    "        # 定义RNN层来更好提取序列特征，此处为双向LSTM输出为2 x hidden_size，可尝试换成GRU等RNN结构\n",
    "        self.lstm = paddle.nn.LSTM(input_size=128,\n",
    "                               hidden_size=64,\n",
    "                               direction=\"bidirectional\")\n",
    "        # 定义输出层，输出大小为分类数\n",
    "        self.linear2 = paddle.nn.Linear(in_features=64 * 2,\n",
    "                                    out_features=CLASSIFY_NUM)\n",
    "\n",
    "    def forward(self, ipt):\n",
    "        # 卷积 + ReLU + BN\n",
    "        x = self.conv1(ipt)\n",
    "        x = paddle.nn.functional.relu(x)\n",
    "        x = self.bn1(x)\n",
    "        # 卷积 + ReLU + BN\n",
    "        x = self.conv2(x)\n",
    "        x = paddle.nn.functional.relu(x)\n",
    "        x = self.bn2(x)\n",
    "        # 卷积 + ReLU\n",
    "        x = self.conv3(x)\n",
    "        x = paddle.nn.functional.relu(x)\n",
    "        # 将3维特征转换为2维特征 - 此处可以使用reshape代替\n",
    "        x = paddle.tensor.flatten(x, 2)\n",
    "        # 全连接 + ReLU\n",
    "        x = self.linear(x)\n",
    "        x = paddle.nn.functional.relu(x)\n",
    "        # 双向LSTM - [0]代表取双向结果，[1][0]代表forward结果,[1][1]代表backward结果，详细说明可在官方文档中搜索'LSTM'\n",
    "        x = self.lstm(x)[0]\n",
    "        # 输出层 - Shape = (Batch Size, Max label len, Signal) \n",
    "        x = self.linear2(x)\n",
    "\n",
    "        # 在计算损失时ctc-loss会自动进行softmax，所以在预测模式中需额外做softmax获取标签概率\n",
    "        if self.is_infer:\n",
    "            # 输出层 - Shape = (Batch Size, Max label len, Prob) \n",
    "            x = paddle.nn.functional.softmax(x)\n",
    "            # 转换为标签\n",
    "            x = paddle.argmax(x, axis=-1)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据集路径设置\n",
    "DATA_PATH = r\"F:\\dataset\\validation_code\"\n",
    "# 训练轮数\n",
    "EPOCH = 10\n",
    "# 每批次数据大小\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "label_define = paddle.static.InputSpec(shape=[-1, LABEL_MAX_LEN],\n",
    "                                    dtype=\"int32\",\n",
    "                                    name=\"label\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CTCLoss(paddle.nn.Layer):\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        定义CTCLoss\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, ipt, label):\n",
    "        input_lengths = paddle.full(shape=[BATCH_SIZE],fill_value=LABEL_MAX_LEN + 4,dtype= \"int64\")\n",
    "        label_lengths = paddle.full(shape=[BATCH_SIZE],fill_value=LABEL_MAX_LEN,dtype= \"int64\")\n",
    "        # 按文档要求进行转换dim顺序\n",
    "        ipt = paddle.tensor.transpose(ipt, [1, 0, 2])\n",
    "        # 计算loss\n",
    "        loss = paddle.nn.functional.ctc_loss(ipt, label, input_lengths, label_lengths, blank=10)\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss value printed in the log is the current step, and the metric is the average value of previous steps.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\.conda\\envs\\paddle\\lib\\site-packages\\paddle\\nn\\layer\\norm.py:777: UserWarning: When training, we now always track global mean and variance.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 526/526 [==============================] - loss: 0.7131 - 102ms/step          \n",
      "save checkpoint at g:\\workspace_github\\ai_application\\validation_code_ocr\\output\\0\n",
      "Eval begin...\n",
      "step 64/64 [==============================] - loss: 0.6287 - 89ms/step          \n",
      "Eval samples: 1024\n",
      "Epoch 2/10\n",
      "step  10/526 [..............................] - loss: 0.6877 - ETA: 6s - 13ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\.conda\\envs\\paddle\\lib\\site-packages\\paddle\\nn\\layer\\norm.py:777: UserWarning: When training, we now always track global mean and variance.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 526/526 [==============================] - loss: 0.2892 - 11ms/step          \n",
      "save checkpoint at g:\\workspace_github\\ai_application\\validation_code_ocr\\output\\1\n",
      "Eval begin...\n",
      "step 64/64 [==============================] - loss: 0.1473 - 9ms/step          \n",
      "Eval samples: 1024\n",
      "Epoch 3/10\n",
      "step  10/526 [..............................] - loss: 0.3765 - ETA: 7s - 14ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\.conda\\envs\\paddle\\lib\\site-packages\\paddle\\nn\\layer\\norm.py:777: UserWarning: When training, we now always track global mean and variance.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 526/526 [==============================] - loss: 0.0732 - 10ms/step          \n",
      "save checkpoint at g:\\workspace_github\\ai_application\\validation_code_ocr\\output\\2\n",
      "Eval begin...\n",
      "step 64/64 [==============================] - loss: 0.0701 - 8ms/step          \n",
      "Eval samples: 1024\n",
      "Epoch 4/10\n",
      "step  10/526 [..............................] - loss: 0.1435 - ETA: 6s - 13ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\.conda\\envs\\paddle\\lib\\site-packages\\paddle\\nn\\layer\\norm.py:777: UserWarning: When training, we now always track global mean and variance.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 526/526 [==============================] - loss: 0.0321 - 11ms/step          \n",
      "save checkpoint at g:\\workspace_github\\ai_application\\validation_code_ocr\\output\\3\n",
      "Eval begin...\n",
      "step 64/64 [==============================] - loss: 0.0388 - 9ms/step          \n",
      "Eval samples: 1024\n",
      "Epoch 5/10\n",
      "step  10/526 [..............................] - loss: 0.1890 - ETA: 6s - 12ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\.conda\\envs\\paddle\\lib\\site-packages\\paddle\\nn\\layer\\norm.py:777: UserWarning: When training, we now always track global mean and variance.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 526/526 [==============================] - loss: 0.0436 - 10ms/step          \n",
      "save checkpoint at g:\\workspace_github\\ai_application\\validation_code_ocr\\output\\4\n",
      "Eval begin...\n",
      "step 64/64 [==============================] - loss: 0.0337 - 9ms/step          \n",
      "Eval samples: 1024\n",
      "Epoch 6/10\n",
      "step  10/526 [..............................] - loss: 0.0305 - ETA: 6s - 12ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\.conda\\envs\\paddle\\lib\\site-packages\\paddle\\nn\\layer\\norm.py:777: UserWarning: When training, we now always track global mean and variance.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 526/526 [==============================] - loss: 0.0881 - 10ms/step          \n",
      "save checkpoint at g:\\workspace_github\\ai_application\\validation_code_ocr\\output\\5\n",
      "Eval begin...\n",
      "step 64/64 [==============================] - loss: 0.0223 - 9ms/step          \n",
      "Eval samples: 1024\n",
      "Epoch 7/10\n",
      "step  10/526 [..............................] - loss: 0.2936 - ETA: 6s - 12ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\.conda\\envs\\paddle\\lib\\site-packages\\paddle\\nn\\layer\\norm.py:777: UserWarning: When training, we now always track global mean and variance.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 526/526 [==============================] - loss: 0.0183 - 10ms/step          \n",
      "save checkpoint at g:\\workspace_github\\ai_application\\validation_code_ocr\\output\\6\n",
      "Eval begin...\n",
      "step 64/64 [==============================] - loss: 0.0170 - 9ms/step          \n",
      "Eval samples: 1024\n",
      "Epoch 8/10\n",
      "step  10/526 [..............................] - loss: 0.0267 - ETA: 7s - 14ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\.conda\\envs\\paddle\\lib\\site-packages\\paddle\\nn\\layer\\norm.py:777: UserWarning: When training, we now always track global mean and variance.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 526/526 [==============================] - loss: 0.0127 - 11ms/step          \n",
      "save checkpoint at g:\\workspace_github\\ai_application\\validation_code_ocr\\output\\7\n",
      "Eval begin...\n",
      "step 64/64 [==============================] - loss: 0.0138 - 10ms/step          \n",
      "Eval samples: 1024\n",
      "Epoch 9/10\n",
      "step  10/526 [..............................] - loss: 0.0178 - ETA: 6s - 13ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\.conda\\envs\\paddle\\lib\\site-packages\\paddle\\nn\\layer\\norm.py:777: UserWarning: When training, we now always track global mean and variance.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 526/526 [==============================] - loss: 0.0162 - 11ms/step          \n",
      "save checkpoint at g:\\workspace_github\\ai_application\\validation_code_ocr\\output\\8\n",
      "Eval begin...\n",
      "step 64/64 [==============================] - loss: 0.0110 - 9ms/step          \n",
      "Eval samples: 1024\n",
      "Epoch 10/10\n",
      "step  10/526 [..............................] - loss: 0.0169 - ETA: 6s - 13ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\.conda\\envs\\paddle\\lib\\site-packages\\paddle\\nn\\layer\\norm.py:777: UserWarning: When training, we now always track global mean and variance.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 526/526 [==============================] - loss: 0.0145 - 10ms/step          \n",
      "save checkpoint at g:\\workspace_github\\ai_application\\validation_code_ocr\\output\\9\n",
      "Eval begin...\n",
      "step 64/64 [==============================] - loss: 0.0119 - 9ms/step          \n",
      "Eval samples: 1024\n",
      "save checkpoint at g:\\workspace_github\\ai_application\\validation_code_ocr\\output\\final\n"
     ]
    }
   ],
   "source": [
    "# 实例化模型\n",
    "model = paddle.Model(Net(), inputs=input_define, labels=label_define)\n",
    "# 定义优化器\n",
    "optimizer = paddle.optimizer.Adam(learning_rate=0.0001, parameters=model.parameters())\n",
    "\n",
    "# 为模型配置运行环境并设置该优化策略\n",
    "model.prepare(optimizer=optimizer,\n",
    "                loss=CTCLoss())\n",
    "# 执行训练\n",
    "model.fit(train_data=Reader(DATA_PATH),\n",
    "            eval_data=Reader(DATA_PATH, is_val=True),\n",
    "            batch_size=BATCH_SIZE,\n",
    "            epochs=EPOCH,\n",
    "            save_dir=\"output/\",\n",
    "            save_freq=1,\n",
    "            verbose=1,\n",
    "            drop_last=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\.conda\\envs\\paddle\\lib\\site-packages\\paddle\\io\\reader.py:433: UserWarning: DataLoader with multi-process mode is not supported on MacOs and Windows currently. Please use signle-process mode with num_workers = 0 instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: StepDecay set learning rate to 0.0001.\n",
      "-------第 1 轮训练开始-------\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Model' object has no attribute 'forward'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 49\u001b[0m\n\u001b[0;32m     47\u001b[0m epoch_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-------第 \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m 轮训练开始-------\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m---> 49\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     50\u001b[0m scheduler\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39m_learning_rate\u001b[38;5;241m.\u001b[39mstep()\u001b[38;5;250m \u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;250m \u001b[39mlr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[12], line 33\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index, (imgs, labels) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_data_loader):\n\u001b[0;32m     32\u001b[0m     imgs, labels \u001b[38;5;241m=\u001b[39m imgs\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m), labels\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mint64\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 33\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m(imgs)\n\u001b[0;32m     34\u001b[0m     input_lengths \u001b[38;5;241m=\u001b[39m paddle\u001b[38;5;241m.\u001b[39mfull((labels\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m],), \u001b[38;5;241m8\u001b[39m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mint64\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     35\u001b[0m     target_lengths \u001b[38;5;241m=\u001b[39m paddle\u001b[38;5;241m.\u001b[39mfull((labels\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m],), \u001b[38;5;241m4\u001b[39m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mint64\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Model' object has no attribute 'forward'"
     ]
    }
   ],
   "source": [
    "import paddle\n",
    "import paddle.optimizer as optim\n",
    "from paddle.io import DataLoader\n",
    "\n",
    "# 数据集路径设置\n",
    "DATA_PATH = r\"F:\\dataset\\validation_code\"\n",
    "batch_size = 128 * 2\n",
    "# 训练轮数\n",
    "EPOCH = 10\n",
    "device = paddle.set_device(\"gpu\" if paddle.is_compiled_with_cuda() else \"cpu\")\n",
    "lr = 0.0001\n",
    "train_data = Reader(DATA_PATH)\n",
    "train_data_loader = DataLoader(\n",
    "    train_data, batch_size=batch_size, shuffle=True, num_workers=2\n",
    ")\n",
    "\n",
    "# model = paddle.Model(Net())\n",
    "model = paddle.Model(Net(), inputs=input_define, labels=label_define)\n",
    "model.prepare(\n",
    "    optim.Adam(learning_rate=lr, parameters=model.parameters()),\n",
    "    paddle.nn.CTCLoss(blank=10),\n",
    ")\n",
    "\n",
    "scheduler = paddle.optimizer.lr.StepDecay(\n",
    "    learning_rate=lr, step_size=2, gamma=0.1, verbose=True\n",
    ")\n",
    "optimal_model = {\"loss\": 1000000, \"stat\": model.parameters(), \"lr\": 0.1}\n",
    "\n",
    "def train():\n",
    "    global epoch_loss\n",
    "    for index, (imgs, labels) in enumerate(train_data_loader):\n",
    "        imgs, labels = imgs.astype(\"float32\"), labels.astype(\"int64\")\n",
    "        outputs = model.forward(imgs)\n",
    "        input_lengths = paddle.full((labels.shape[0],), 8, dtype=\"int64\")\n",
    "        target_lengths = paddle.full((labels.shape[0],), 4, dtype=\"int64\")\n",
    "        outputs = paddle.transpose(outputs, perm=[1, 0, 2])\n",
    "        loss = model.criterion(outputs, labels, input_lengths, target_lengths)\n",
    "        loss_value = loss.numpy()[0]\n",
    "        loss.backward()\n",
    "        model._optimizer.step()\n",
    "        model._optimizer.clear_grad()\n",
    "        # 打印训练信息\n",
    "        epoch_loss += loss_value\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    for i in range(EPOCH):\n",
    "        epoch_loss = 0\n",
    "        print(\"-------第 {} 轮训练开始-------\".format(i + 1))\n",
    "        train()\n",
    "        scheduler.step()\n",
    "        print(f'lr: {model.optimizer._learning_rate.step() * lr}')\n",
    "\n",
    "        print(f\"epoch: {i} loss: {epoch_loss}\")\n",
    "        # 保存模型\n",
    "        # if epoch_loss < optimal_model[\"loss\"]:\n",
    "        if epoch_loss < 1000:\n",
    "            optimal_model[\"loss\"] = epoch_loss\n",
    "            optimal_model[\"stat\"] = model.parameters()\n",
    "            optimal_model[\"lr\"] = model.optimizer._learning_rate.step() * lr\n",
    "            if not os.path.isdir(\"checkpoint\"):\n",
    "                os.mkdir(\"checkpoint\")\n",
    "            paddle.save(\n",
    "                optimal_model,\n",
    "                os.path.join(os.getcwd(), \"checkpoint\", f\"ckpt-{epoch_loss}.pdparams\"),\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SHAPE_H = 30\n",
    "IMAGE_SHAPE_W = 70\n",
    "\n",
    "# 与训练近似，但不包含Label\n",
    "class InferReader(Dataset):\n",
    "    def __init__(self, dir_path=None, img_path=None):\n",
    "        \"\"\"\n",
    "        数据读取Reader(预测)\n",
    "        :param dir_path: 预测对应文件夹（二选一）\n",
    "        :param img_path: 预测单张图片（二选一）\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        if dir_path:\n",
    "            # 获取文件夹中所有图片路径\n",
    "            self.img_names = [i for i in os.listdir(dir_path) if os.path.splitext(i)[1] == \".jpg\"]\n",
    "            self.img_paths = [os.path.join(dir_path, i) for i in self.img_names]\n",
    "        elif img_path:\n",
    "            self.img_names = [os.path.split(img_path)[1]]\n",
    "            self.img_paths = [img_path]\n",
    "        else:\n",
    "            raise Exception(\"请指定需要预测的文件夹或对应图片路径\")\n",
    "\n",
    "    def get_names(self):\n",
    "        \"\"\"\n",
    "        获取预测文件名顺序 \n",
    "        \"\"\"\n",
    "        return self.img_names\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # 获取图像路径\n",
    "        file_path = self.img_paths[index]\n",
    "        # 使用Pillow来读取图像数据并转成Numpy格式\n",
    "        img = Image.open(file_path).resize((IMAGE_SHAPE_W, IMAGE_SHAPE_H))\n",
    "        img = np.array(img, dtype=\"float32\").reshape((IMAGE_SHAPE_C, IMAGE_SHAPE_H, IMAGE_SHAPE_W)) / 255\n",
    "        return img\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 待预测目录 - 可在测试数据集中挑出\\b3张图像放在该目录中进行推理\n",
    "INFER_DATA_PATH = \"./sample_img\"\n",
    "# 训练后存档点路径 - final 代表最终训练所得模型\n",
    "CHECKPOINT_PATH = \"./output/final.pdparams\"\n",
    "# 每批次处理数量\n",
    "BATCH_SIZE = 32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict begin...\n",
      "step 1/1 [==============================] - 2s/step\n",
      "Predict samples: 2\n",
      "文件名：8403.jpg，推理结果为：[7, 4]\n",
      "文件名：9264.jpg，推理结果为：[3, 9, 5, 2]\n"
     ]
    }
   ],
   "source": [
    "# 编写简易版解码器\n",
    "def ctc_decode(text, blank=10):\n",
    "    \"\"\"\n",
    "    简易CTC解码器\n",
    "    :param text: 待解码数据\n",
    "    :param blank: 分隔符索引值\n",
    "    :return: 解码后数据\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    cache_idx = -1\n",
    "    for char in text:\n",
    "        if char != blank and char != cache_idx:\n",
    "            result.append(char)\n",
    "        cache_idx = char\n",
    "    return result\n",
    "\n",
    "\n",
    "# 实例化推理模型\n",
    "model = paddle.Model(Net(is_infer=True), inputs=input_define)\n",
    "# 加载训练好的参数模型\n",
    "model.load(CHECKPOINT_PATH)\n",
    "# 设置运行环境\n",
    "model.prepare()\n",
    "\n",
    "# 加载预测Reader\n",
    "infer_reader = InferReader(INFER_DATA_PATH)\n",
    "img_names = infer_reader.get_names()\n",
    "results = model.predict(infer_reader, batch_size=BATCH_SIZE)\n",
    "index = 0\n",
    "for text_batch in results[0]:\n",
    "    for prob in text_batch:\n",
    "        out = ctc_decode(prob, blank=10)\n",
    "        print(f\"文件名：{img_names[index]}，推理结果为：{out}\")\n",
    "        index += 1\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paddle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
